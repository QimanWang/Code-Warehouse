{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Basic Gradient Descent\n",
    "\n",
    "Gradient descent is an important algorithm for minimizing a function.  Having an algorithm to minimize a function is quite powerful:  you can maximize a function $f$ by minimizing $-f$ and you can solve a system of equations $f_1=k_1, f_2=k_2, \\cdots f_r=k_r$ by minimizing $(f_1-k_1)^2+(f_2-k_2)^2+\\cdots (f_r-k_r)^2$.  \n",
    "\n",
    "Here's an example, in one variable, implemented in python, from <a href=\"https://en.wikipedia.org/wiki/Gradient_descent#Computational_examples\">https://en.wikipedia.org/wiki/Gradient_descent#Computational_examples</a>.  The program finds the minimum of\n",
    "$ f(x) =x^4âˆ’3x^3+2. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# From calculation, it is expected that the local minimum occurs at x=9/4\n",
    "\n",
    "cur_x = 6 # The algorithm starts at x=6\n",
    "gamma = 0.01 # step size multiplier\n",
    "precision = 0.00001\n",
    "previous_step_size = cur_x\n",
    "\n",
    "def df(x):\n",
    "    return 4 * x**3 - 9 * x**2\n",
    "\n",
    "while previous_step_size > precision:\n",
    "    prev_x = cur_x\n",
    "    cur_x += -gamma * df(prev_x)\n",
    "    previous_step_size = abs(cur_x - prev_x)\n",
    "\n",
    "print(\"The local minimum occurs at %f\" % cur_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To explain how gradient descent works and visualize the algorithm geometrically, it will help to recall a bit about gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A quick review about gradients and two important facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The gradient of a differentiable function $g:\\mathbb{R}^n \\to \\mathbb{R}$ is defined to be the unique vector field $\\nabla g$ with the property that for each point $x\\in \\mathbb{R}^n$, $$\\langle \\nabla g(x), v\\rangle = D_v g(x).$$\n",
    "Here, $\\langle \\, , \\, \\rangle$ denotes the inner product (dot product) of vectors and $D_v g(x)$ denotes the directional derivative of $g$ at the point $x$ in the direction $v$:\n",
    "$$D_v g(x)=\\lim_{h \\to 0} \\frac{g(x+hv)-g(x)}{h}.$$\n",
    "In standard coordinates, the gradient can be computed as\n",
    "$$\\nabla g(x)=\\left [ \\frac{\\partial g}{\\partial x_0} (x), \\frac{\\partial g}{\\partial x_1} (x), \\ldots, \\frac{\\partial g}{\\partial x_{n-1}} (x) \\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Steepest Descent\n",
    "\n",
    "Recall that $\\langle v,w \\rangle=\\|v\\|w\\| \\cos(\\theta)$ where $\\theta$ is the angle between the vectors $v$ and $w$.  Therefore, if $v$ is a unit vector, \n",
    "\n",
    "$$D_v g(x)=\\langle \\nabla g(x), v\\rangle =\\|\\nabla g(x)\\| \\cos(\\theta)$$\n",
    "\n",
    "is maximized when $v$ points in the direction of the gradient $\\nabla g(x)$ and minimized when $v$ points in the direction $-\\nabla g(x)$.\n",
    "\n",
    "<strong>Conclusion</strong> $-\\nabla g(x)$ is the direction of steepest descent for the function $g$ at the point $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Perpendicular to level curves\n",
    "\n",
    "The level set of $g:\\mathbb{R}^n \\to \\mathbb{R}$ of level $k\\in \\mathbb{R}$ is defined to be the set\n",
    "\n",
    "$$g^{-1}(k)=\\{(x_0,x_1,  \\ldots, x_{n-1})\\in \\mathbb{R}^n: g(x_0,x_1,  \\ldots, x_{n-1})=k\\}$$\n",
    "\n",
    "If $:\\alpha: t\\mapsto (x_0(t),x_1(t),  \\ldots, x_{n-1}(t))$ is a curve in a level set of $g$, then the the function $\\mathbb{R} \\overset{\\alpha}{\\to} \\mathbb{R}^n \\overset{g}{\\to} \\mathbb{R}$ is constant and hence has zero derivative.  Keeping the multivariable chain rule in mind, we have\n",
    "\n",
    "$$Dg \\circ d\\alpha = 0 \\Longleftrightarrow \\begin{bmatrix} \\frac{\\partial g}{\\partial x_0} (x)& \\frac{\\partial g}{\\partial x_1} (x)& \\ldots & \\frac{\\partial g}{\\partial x_{n-1}} (x) \\end{bmatrix} \\begin{bmatrix} x_0'(t) \\\\ x_1'(t) \\\\ \\vdots \\\\ x_{n-1}'(t)\\end{bmatrix} = 0.$$\n",
    "\n",
    "In other words, the gradient $\\nabla g(x)$ is perpendicular to the level sets of $g$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let's do some programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following line is a Jupyter code that tells matplotlib to display graphics inline within the jupyter notbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "def f(x):\n",
    "    return  x**4 - 3 * x**3+2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here's how to evaluate this function at a number, say $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To plot this function, we make a bunch of (x,y) coordinates on the graph.  Before doing this, let's take a look at ways we can operate on elements in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x = np.linspace(0,3,7) # make an array of 7 evenly spaced numbers between 0 and 5\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "y=x**2 # squares every number in the list\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "'scatter' plots the points as dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7])\n",
    "axes.scatter(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and 'plot' connects the dots with straight lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7])\n",
    "axes.plot(x,y, label=r'$y = x^2$')\n",
    "axes.legend(loc=2); # upper left corner;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To get a better picture, we'll use a lot more points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "x = np.linspace(0,6,1001)\n",
    "y = f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7])\n",
    "axes.plot(x,y, label=r'$y = x^4 - 3  x^3+2$')\n",
    "axes.legend(loc=2); # upper left corner;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, back to gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "cur_x = 6 # The algorithm starts at x=6\n",
    "gamma = 0.01 # step size multiplier\n",
    "precision = 0.00001\n",
    "previous_step_size = cur_x\n",
    "\n",
    "x_list = [cur_x]; y_list = [f(cur_x)]\n",
    "\n",
    "def df(x):\n",
    "    return 4 * x**3 - 9 * x**2\n",
    "\n",
    "while previous_step_size > precision:\n",
    "    prev_x = cur_x\n",
    "    cur_x += -gamma * df(prev_x)\n",
    "    previous_step_size = abs(cur_x - prev_x)\n",
    "    x_list.append(cur_x)\n",
    "    y_list.append(f(cur_x))\n",
    "\n",
    "print \"Local minimum occurs at:\", cur_x\n",
    "print \"Number of steps:\", len(x_list)\n",
    "print \"Minimum value:\", f(cur_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7]) # left, bottom, width, height (range 0 to 1)\n",
    "axes.plot(x,y, 'g', label=r'$y = x^4-3x^3+2$') # g for green\n",
    "axes.scatter(x_list,y_list,c=\"r\")\n",
    "axes.plot(x_list,y_list,c=\"r\",label='gradient descent steps')\n",
    "axes.legend(loc=2); # upper left corner\n",
    "axes.set_xlabel('$x$')\n",
    "axes.set_ylabel('$y$') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "xzoom = np.linspace(0,2.5,100)\n",
    "yzoom=f(xzoom)\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 12, 'text.usetex': True})\n",
    "\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7]) # left, bottom, width, height (range 0 to 1)\n",
    "axes.plot(xzoom,yzoom, 'g', label=r'$y = x^4-3x^3+2$') # g for green\n",
    "axes.scatter(x_list[8:],y_list[8:],c=\"r\")\n",
    "axes.plot(x_list[8:],y_list[8:],c=\"r\",label='gradient descent steps')\n",
    "axes.legend(loc=1); # upper right corner\n",
    "axes.set_xlabel('$x$')\n",
    "axes.set_ylabel('$y$') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 dimensional example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here we consider a function $g:\\mathbb{R}^2 \\to \\mathbb{R}$ defined by $g(x_0,x_1)=3(x_0-2)^2+(x_1-1)^2$.  We define $g$ as a function of $x$, where $x$ should be a list $[x_0,x_1].$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "def g(x):\n",
    "    return 3*(x[0]-2)**2+(x[1]-1)**2+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "def grad_g(x):\n",
    "    return np.array([6*(x[0]-2), 2.0*(x[1]-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x_old = np.array([0,4])\n",
    "h = 0.1 # step size\n",
    "precision = 0.001\n",
    "\n",
    "x_list = [x_old]\n",
    "z_list = [g(x_old)]\n",
    "\n",
    "x_new = x_old - h * grad_g(x_old)\n",
    "x_list.append(x_new)\n",
    "z_list.append(g(x_new))\n",
    "\n",
    "while (abs(x_new[0] - x_old[0])+abs(x_new[1] - x_old[1])) > precision:\n",
    "    x_old = x_new\n",
    "    direction = - grad_g(x_old)\n",
    "    x_new = x_old + h * direction\n",
    "    x_list.append(x_new)\n",
    "    z_list.append(g(x_new))\n",
    "print \"Local minimum occurs at:\", x_new\n",
    "print \"Number of steps:\", len(x_list)\n",
    "print \"minimum value is:\", g(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
    "x0 = np.linspace(-1,6,100)\n",
    "x1 = np.linspace(-2,5,100)\n",
    "X0, X1 = np.meshgrid(x0,x1)\n",
    "Z=g([X0,X1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x0_coordlist=np.array(x_list)[:,0]\n",
    "x1_coordlist=np.array(x_list)[:,1]\n",
    "z_coordlist=np.array(z_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "plt.figure()\n",
    "plt.contour(X0,X1,Z,50) # this plots level sets\n",
    "plt.plot(x0_coordlist,x1_coordlist,c=\"r\"); # here is the gradient path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "#ax = fig.add_subplot(1,1,1, projection='3d')\n",
    "#ax=gca(projection='3d')\n",
    "#fig = plt.figure()\n",
    "ax = fig.gca (projection='3d')\n",
    "ax.plot_wireframe(X0, X1, Z, rcount=10, ccount=10);\n",
    "ax.plot_surface(X0, X1, Z, alpha=0.25)\n",
    "ax.plot(x0_coordlist,x1_coordlist,z_coordlist,c=\"r\")\n",
    "ax.view_init(20, -80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Homework\n",
    "\n",
    "Suppose that you have data consisting of points in the $x$-$y$ plane\n",
    "\n",
    "$$(x_0,y_0),(x_1,y_1),\\ldots, (x_N,y_N)$$\n",
    "\n",
    "and you'd like to find a degree $d$ polynomial $p(x)=a_0 +a_1 x +a_2 x^2 + \\cdots + a_d x^d$ that best fits the data.\n",
    "\n",
    "One way to proceed is to think of the coefficients $a_0, \\ldots, a_d$ of the polynomial as variables and to minimize the function \n",
    "\n",
    "$$C(a_0, \\ldots, a_d)=\\sum_{i=0}^N (y_i - p(x_i))^2.$$\n",
    "\n",
    "Your problem: find the best degree $5$ polynomial that fits the data from the file datafile.npy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cbe20bfe3d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datafile.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# load the data:\n",
    "data=np.load('datafile.npy')\n",
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7]) \n",
    "axes.scatter(data[:,0],data[:,1],c=\"r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}