{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dsigmoid(x):\n",
    "    s=sigmoid(x)\n",
    "    return s*(1-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Network parameters is represnted as [$\\alpha^0,\\theta^0_{0},\\theta^0_{1},\\alpha^1,\\theta^1_{0},\\theta^1_{1},\\alpha^2,\\theta^2_{0},\\theta^2_{1},\\alpha^3,\\theta^3_{0},\\theta^3_{1}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def network_function(network_params,x):\n",
    "    first_term = network_params[0] * sigmoid(network_params[1]+ network_params[2] * x)\n",
    "    second_term = network_params[3] * sigmoid(network_params[4] + network_params[5]* x)\n",
    "    third_term = network_params[6] * sigmoid(network_params[7] + network_params[8]* x)\n",
    "    fourth_term = network_params[9] * sigmoid(network_params[10] + network_params[11]* x)\n",
    "    return first_term + second_term + third_term + fourth_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def inner_product(f,g,network_params):\n",
    "    points = np.linspace(0,2 * np.pi,100)\n",
    "    sum = 0\n",
    "    for point in points:\n",
    "        sum = sum + f(network_params,point) * g(network_params,point)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Cost function\n",
    "def norm_of_u_minus_sin_squared(network_params):\n",
    "    u = network_function\n",
    "    #x is input to sine and network\n",
    "    u_minus_sin = lambda network_params,x: u(network_params,x) - np.sin(x)\n",
    "    return  (inner_product(u_minus_sin,u_minus_sin,network_params)) / 200.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "data = np.linspace(0,2 * np.pi,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def gradcost(theta):\n",
    "    gradvect=np.zeros(12)\n",
    "    for x in data:\n",
    "        dcostdmu=(network_function(theta,x)-np.sin(x))\n",
    "        for i in range(0,12,3):\n",
    "            term=dcostdmu*theta[i]*dsigmoid(theta[i+1]+theta[i+2]*x)\n",
    "            gradvect[i]+=dcostdmu*sigmoid(theta[i+1]+theta[i+2]*x)\n",
    "            gradvect[i+1]+=term\n",
    "            gradvect[i+2]+=term*x\n",
    "    return 1.0/100*gradvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Does Forward difference in each dimension\n",
    "def eval_numerical_gradient(f, x):\n",
    "    \"\"\" \n",
    "    a naive implementation of numerical gradient of f at x\n",
    "    - f should be a function that takes a single argument\n",
    "    - x is the point (numpy array) to evaluate the gradient at\n",
    "    \"\"\"\n",
    "    fx = f(x) # evaluate function value at original point\n",
    "    grad = np.zeros(x.shape)\n",
    "    h = 0.00001\n",
    "\n",
    "    # iterate over all indexes in x\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "\n",
    "        # evaluate function at x+h\n",
    "        ix = it.multi_index\n",
    "        old_value = x[ix]\n",
    "        x[ix] = old_value + h # increment by h\n",
    "        fxh = f(x) # evalute f(x + h)\n",
    "        x[ix] = old_value # restore to previous value (very important!)\n",
    "        # compute the partial derivative\n",
    "        grad[ix] = (fxh - fx) / h # the slope\n",
    "        it.iternext() # step to next dimension\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "mytheta0 = np.random.rand(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "numgrad = eval_numerical_gradient(norm_of_u_minus_sin_squared,mytheta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.83123405e-06  -3.96846139e-07  -5.69111473e-06   4.31887614e-06\n",
      "  -7.26066509e-08  -4.96932604e-07   1.66334332e-06  -1.16705629e-07\n",
      "  -2.94403583e-06   3.22880348e-06  -3.73808780e-07  -6.62361799e-06]\n"
     ]
    }
   ],
   "source": [
    "print (numgrad-gradcost(mytheta0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with initial coefficients [ 0.14972113  0.69251867  0.5541395   0.09615764  0.18080972  0.71975808\n",
      "  0.84516115  0.37957641  0.61062095  0.08438766  0.3494913   0.72804208]\n",
      "domain values within tolerance  1e-10\n",
      "Local minimum occurs at: [ 0.14972094  0.69251847  0.5541393   0.09615745  0.18080953  0.71975789\n",
      "  0.84516096  0.37957621  0.61062075  0.08438746  0.34949111  0.72804189]\n",
      "Number of steps: 2\n",
      "minimum value is: 0.843982972778\n"
     ]
    }
   ],
   "source": [
    "a_old = np.random.rand(12) # start with random coefficients instead of zeros\n",
    "print (\"Starting with initial coefficients\", a_old)\n",
    "h = 10**(-7) # step size\n",
    "tol_1 = 10**(-10) # stop if change in coefficients is less than tol_1\n",
    "tol_2 = 10**(-10) # stop if change in total cost is less than tol_2\n",
    "max_steps = 500 # stop if total number of steps exceeds max_steps\n",
    "\n",
    "a_list = [a_old]\n",
    "z_list = [norm_of_u_minus_sin_squared(a_old)]\n",
    "unit_grad = np.linalg.norm(eval_numerical_gradient(norm_of_u_minus_sin_squared,a_old))\n",
    "a_new = a_old - h * unit_grad\n",
    "a_list.append(a_new)\n",
    "z_list.append(norm_of_u_minus_sin_squared(a_new))\n",
    "\n",
    "for i in range(max_steps):\n",
    "    if sum((a_new-a_old)**2) < tol_1:\n",
    "        print (\"domain values within tolerance \", tol_1)\n",
    "        break\n",
    "    if abs(z_list[-1] - z_list[-2])<tol_2:\n",
    "        print (\"cost values within tolerance \", tol_2)\n",
    "        break\n",
    "    a_old = a_new\n",
    "    unit_grad = np.linalg.norm(eval_numerical_gradient(norm_of_u_minus_sin_squared,a_old))\n",
    "    a_new = a_old - h * unit_grad\n",
    "    a_list.append(a_new)\n",
    "    z_list.append(norm_of_u_minus_sin_squared(a_new))\n",
    "\n",
    "\n",
    "print (\"Local minimum occurs at:\", a_new)\n",
    "print (\"Number of steps:\", len(a_list))\n",
    "print (\"minimum value is:\", norm_of_u_minus_sin_squared(a_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x_0 = np.linspace(0, 2 * np.pi,100)\n",
    "y_0 = []\n",
    "y_1 = []\n",
    "for p in x_0:\n",
    "    y_0.append(network_function(a_new,p))\n",
    "    y_1.append(np.sin(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7b88a0dfd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "a361f8f59361e59ba41a80f2d3b67efcec5bc346"
     },
     "metadata": {
      "image/png": {
       "height": 234,
       "width": 436
      }
     }
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7])\n",
    "axes.plot(x_0,y_0,label =\"Gradient Descent\",c = \"red\");\n",
    "axes.plot(x_0,y_1, label = \"Sine Function\", c = \"blue\")\n",
    "axes.legend(loc = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Perhaps should use gradient descent that uses parabola"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda)",
   "language": "python",
   "name": "anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}