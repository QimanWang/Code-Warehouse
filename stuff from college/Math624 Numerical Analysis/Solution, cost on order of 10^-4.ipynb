{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Here we can specify wether we want large input data or small input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "sizeOfTrainingData = 100 # choose between 100, 200 or more\n",
    "learningRate = 4 #choose between 2 ,4 ,or 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def my_grad_desc(g,dg,x,tol_1,tol_2,max_steps):\n",
    "    counter =0\n",
    "    for i in range(max_steps):\n",
    "        #print i,x,g(x)\n",
    "        g0 = g(x)\n",
    "        grad = dg(x)\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "        counter +=1\n",
    "        if counter % 300 == 0:\n",
    "            print norm_grad\n",
    "        if norm_grad < tol_1:\n",
    "            #print \"gradient norm less than \", tol_1\n",
    "            #print \"min value of \", g0,\" obtained in \",i+1,\" steps.\"\n",
    "            return x\n",
    "            break\n",
    "        unit_grad = (1/norm_grad)*grad\n",
    "        alpha0=0; alpha2=1\n",
    "        g2 = g(x-alpha2*unit_grad)\n",
    "        while g2 >= g0:\n",
    "            alpha2 = 0.5*alpha2\n",
    "            g2 = g(x-alpha2*unit_grad)\n",
    "            if alpha2 < tol_1:\n",
    "                #print \"step size less than \", tol_1\n",
    "                #print \"min value of \", g0,\" obtained in \",i+1,\" steps.\"\n",
    "                return x\n",
    "                break\n",
    "        alpha1 = 0.5*alpha2\n",
    "        g1 = g(x-alpha1*unit_grad)\n",
    "        h0 = (g1-g0)/alpha1\n",
    "        h1 = (g2-g1)/(alpha2-alpha1)\n",
    "        h2 = (h1-h0)/alpha2\n",
    "        alpha0=0.5*(alpha1-h0/h2)\n",
    "        g00=g(x-alpha0*unit_grad)\n",
    "        if abs(g00-g0) < tol_2 :\n",
    "            #print \"functional values less than \", tol_2\n",
    "            return x\n",
    "            break\n",
    "        x = x-alpha0*unit_grad\n",
    "    #print(\"iteration limit reached.  min value of \", g0,\" obtained in \",i+1,\" steps.\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def dsigmoid(x):\n",
    "    s=sigmoid(x)\n",
    "    return s*(1-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def mu(theta,x):\n",
    "    # assuming theta = [t0, t1, ..., t11]\n",
    "    musum=0\n",
    "    for i in range(0,12,3):\n",
    "        musum+=theta[i]*sigmoid(theta[i+1]+theta[i+2]*x)\n",
    "#     if np.amax(x) <=np.pi:\n",
    "#         musum*=-1\n",
    "    return musum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def cost(theta):\n",
    "    totalcost=0\n",
    "    for i in range(sizeOfTrainingData):\n",
    "        totalcost+=(mu(theta,data[i])-y[i])**2\n",
    "    return (1.0/sizeOfTrainingData)*totalcost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def gradcost(theta):\n",
    "    gradvect=np.zeros(12)\n",
    "    for x in data:\n",
    "        dcostdmu=(mu(theta,x)-np.sin(x))\n",
    "        for i in range(0,12,3):\n",
    "            term=dcostdmu*theta[i]*dsigmoid(theta[i+1]+theta[i+2]*x)\n",
    "            gradvect[i]+=dcostdmu*sigmoid(theta[i+1]+theta[i+2]*x)\n",
    "            gradvect[i+1]+=term\n",
    "            gradvect[i+2]+=term*x\n",
    "    return 1.0/sizeOfTrainingData*learningRate*gradvect\n",
    "#hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# We shuffle the data so that the fitting is not sequential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "data=np.linspace(0,np.pi,sizeOfTrainingData)\n",
    "np.random.shuffle(data)\n",
    "y=np.sin(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "x4plotting=np.linspace(0,np.pi,sizeOfTrainingData)\n",
    "y4plotting=np.sin(x4plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The goal here is to only approximate sine from 0 to $\\pi$\n",
    "from $\\pi$ to 2 $\\pi$ we simply just take the negative of sine 0 to $\\pi$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0451942737845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017938668223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00844852895946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00502561941427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00368767664021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00301909845832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved parameters with cost  0.000177496913996  found\n",
      "trial  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0348414746389\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a336c35b327c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m######### theta between certain numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mrandom_theta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msol_theta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_grad_desc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradcost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"improved parameters with cost \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msol_theta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" found\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-1e8561bb75ce>\u001b[0m in \u001b[0;36mmy_grad_desc\u001b[0;34m(g, dg, x, tol_1, tol_2, max_steps)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mg2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mg0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0malpha2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0malpha2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munit_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0malpha2\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtol_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m#print \"step size less than \", tol_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cb9df5f081d4>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtotalcost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizeOfTrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtotalcost\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msizeOfTrainingData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtotalcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-f11eef5123aa>\u001b[0m in \u001b[0;36mmu\u001b[0;34m(theta, x)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmusum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmusum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#     if np.amax(x) <=np.pi:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#         musum*=-1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e0df9e94ae5e>\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_theta=np.zeros(12)\n",
    "best_initial_theta=np.zeros(12)\n",
    "num_trials=10\n",
    "for i in range(num_trials):\n",
    "    print \"trial \",i\n",
    "    ######### theta between certain numbers\n",
    "    random_theta=learningRate*np.random.rand(12)\n",
    "    sol_theta=my_grad_desc(cost,gradcost,random_theta,10**(-11),10**(-11),2000)\n",
    "    if cost(sol_theta)<cost(best_theta):\n",
    "        print \"improved parameters with cost \",cost(sol_theta),\" found\"\n",
    "        best_theta=sol_theta\n",
    "        best_initial_theta=random_theta\n",
    "print \"Trials complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.79163797, -0.95046725,  1.6615755 ,  0.61797605,  3.89490824,\n",
       "        1.94809409, -1.20424054,  3.98770536,  0.94905968, -3.59176858,\n",
       "       -3.04031479,  1.08981579])"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017749691399644973"
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "fb4bafd4f5d80e22abed45cc00b962d57c92bef3"
     }
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.9, 0.7]) \n",
    "ypredicted = mu(best_theta,x4plotting) \n",
    "yfinal = np.append(ypredicted , -1*ypredicted)\n",
    "xfinal = np.linspace(0,2*np.pi,200)\n",
    "axes.plot(xfinal,np.sin(xfinal),c=\"r\");\n",
    "axes.plot(xfinal,yfinal,c=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# fig = plt.figure()\n",
    "# axes = fig.add_axes([0.1, 0.1, 0.9, 0.7]) \n",
    "# axes.plot(xx,yy,c=\"r\");\n",
    "# axes.plot(xx,mu(best_theta,xx),c=\"b\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (SageMath)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}